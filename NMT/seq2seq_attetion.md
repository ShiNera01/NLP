Seq2Seq의 문제점
  - Encoder -> Decoder 진행 중의 문제
  - Encoder의 출력은 '고정 길이 벡터'
    고정 길이는 입력 문장의 길이에 관계 없이 항상 같은 길이 벡터로 변환
    필요한 정보 모두 담기 힘듬
    단어의 사이즈가 커지고 길어지면 문제 됨
    
    
    
    
    
Attention
  - Encoder 개선
  - 마지막 은닉층만 전달하지 않고, 출력의 길이는 입력 문자의 길이에 따라 바꿔 줌
  - 하나의 고정 길이 벡터라는 제약에서 자유로워짐
  - 모든 은닉층에 대해서 가중치를 별도로 계산
  - ex) '나'와'i'에 대한 부분이면 가중치를 높인다. 0.0 ~ 1.0
  
